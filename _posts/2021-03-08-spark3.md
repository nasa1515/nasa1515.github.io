---
layout: post
title: "[DATA] - Azure blob에서 csv data 가져오기 to SPARK"
author: nasa1515
categories: DATA
date: 2021-03-08 12:36
comments: true
cover: "/assets/1800-550.jpg"
tags: DATA
---



## ** Azure blob에서 csv data 가져오기 to SPARK**


<br/>

**머리말**  

**저번 포스트에서 고생을 좀 해가면서 드디어 SPARK Cluster를 구성했습니다.**  
**이번 포스트부터 본격적으로 데이터를 다루기 시작 할 겁니다.**  
**제가 Azure를 사용하기 때문에 아마 가장 많이 사용 할 방식인 blob Storage에 있는**  
**test data를 import, export 하는 방법에 대해서 포스트 했습니다.**  






  


 
---

**DATA 시리즈**

* **이론**


---



**목차**


- [Azure Blob Storage에 csv 파일 Upload](#a1)
- [Spark Cluster에 blob csv 파일 올리기 - ERROR 발생!](#a2)
- [Hadoop 설치 및 연동](#a3)
- [Zeppelin 설치](#a4)
- [pyspark 실행 ERROR 발생 및 해결..](#a5)

--- 

<br/>

## **Azure Blob Storage에 csv 파일 Upload**   <a name="a1"></a>   

**기본적으로 Azure에서 Storage는 Storage Account로 관리됩니다.**  
**때문에 우선적으로 Storage Account를 생성하고 blob container를 생성해야 합니다.**  

* **Storage Account 및 blob의 생성은 [이전포스트](https://nasa1515.github.io/azure/2021/02/08/AZURE-Storageservice.html#a2)를 확인하시면 됩니다.**  

<br/>

#### **저는 다음과 같이 TESTDATA.csv 파일을 blob에 upload 했습니다.**  

![13123123](https://user-images.githubusercontent.com/69498804/110274941-64466100-8013-11eb-8357-ca245d5c6d2f.JPG)


<br/>

---

## **Spark Cluster에 blob csv 파일 올리기 - ERROR 발생!**    <a name="a2"></a> 


* #### **원래의 목표 : hadoop(yarn) - Cluster Manager 없이 Standalone 구성에 blob storage data read.**

    * **해당 구성을 테스트 해보려고 했으나 다음과 같은 ERROR 발생**  

    ![1232313](https://user-images.githubusercontent.com/69498804/110295613-a8962900-8034-11eb-8639-d665dc057275.JPG)


    **해당 이슈는 blob(data lake gen2)에서 wasb[s] 형식으로 파일을 받아오려 했으나**  
    **Spark 가 설치되어있는 VM에는 Hadoop이 설치 및 연동이 되어있지 않기에 DF에 넣을 수 없는 이슈 였습니다.**  
    **사실 pyspark를 기반으로 작동해서 Azure blob api를 직접 선언해서 https 연동을 할 수는 있지만**  
    **그렇게 사용하는 로직은 실습이나 실무에서도 적합하지 않다고 생각해서 Hadoop을 깔기로 했습니다.**  

<br/>

---


## **Hadoop 설치 및 연동**    <a name="a3"></a> 
 