---
layout: post
title: "[DATA] - GCP DataFlow With Python"
author: nasa1515
categories: DATA
date: 2021-04-07 12:36
comments: true
cover: "/assets/1800-550.jpg"
tags: DATA
---



## **GCP DataFlow With Python**


<br/>

**머리말**  

**이번 포스트에서는 GCP의 DataFlow를 사용해서 BigQuery까지의 연동을 다뤄보겠습니다.**  
**물론 파이썬을 첨가해서**  


---

**DATA 시리즈**




**이론**



 - [Apache Spark](https://nasa1515.github.io/data/2021/03/03/spark.html)


**실습** 

 - [Azure Synapse Analytics](https://nasa1515.github.io/data/2021/02/25/azure-synapse.html)
 - [Azure VM에 Apache Spark v3.0 Standalone 설치 With Zeppelin](https://nasa1515.github.io/data/2021/03/04/Spark2.html)
 - [Hadoop 3.3.0 Full Distribute mode infra 구축](https://nasa1515.github.io/data/2021/03/08/hadoop.html)
 - [Apache Spark v3.0 on yarn 설치 With Zeppelin](https://nasa1515.github.io/data/2021/03/10/spark-yarn.html)

---

**목차**


- [DataFlow 환경 구성](#a1)
- [Fluentd 설치](#a2)


--- 

## **DataFlow 환경 구성**    <a name="a1"></a> 

#### **DataFlow 사용하기 위한 환경을 구성하는 것부터 진행하도록 하겠습니다.** 

<br/>

* #### **Project 생성 [DataFlow용]**  

    ![캡처](https://user-images.githubusercontent.com/69498804/113800468-f320d780-9791-11eb-9326-84ad351808b4.JPG)

    * #### **저는 "DataflowTest"라는 이름으로 새로운 프로젝트를 생성했습니다.**  

    <br/>


* #### **이제 프로젝트에서 사용 할 API를 추가해줍니다.**  

    ![캡처2](https://user-images.githubusercontent.com/69498804/113811074-806e2700-97a6-11eb-9e4b-384907be0558.JPG)

    <br/>

    **설치 API 목록**

    * **Cloud Dataflow**
    * **Stackdriver**
    * **Cloud Storage**
    * **Cloud Storage JSON**
    * **BigQuery**
    * **Cloud Pub/Sub**
    * **Cloud Datastore**
    * **Cloud Resource Manager APIs**


    <br/>


* #### **이후 새로운 Service Account를 생성합니다.**

    ![캡처3](https://user-images.githubusercontent.com/69498804/113811448-30439480-97a7-11eb-9a42-4e8425375130.JPG)

    * **권한 : 소유자**  
    * **KeyFile : Json**  

    <br/>

* #### **이제 Cloud Storage를 생성합니다.** 

    ![캡처4](https://user-images.githubusercontent.com/69498804/113811803-d68f9a00-97a7-11eb-8cc0-0d6463f8a42b.JPG)


    * **Storage Class : Standard**
    * **Single Region** 

    <br/>

---

## **이후 작업은 Cloud Shell에서 진행합니다.**  

**저는 local에 Google Cloud SDK을 설치해서 진행했습니다.**  

* **[공식 DOC](https://cloud.google.com/sdk/docs/quickstart-windows?hl=ko)를 참고, 설치 해서 진행하시면 됩니다.**  

    ![캡처5](https://user-images.githubusercontent.com/69498804/113814455-a5659880-97ac-11eb-9d12-a83ac4dfe39a.JPG)


    <br/>


* **저는 Python3.7 을 사용해서 템프릿을 생성하기에 beam을 설치합니다.** 

    ```
    # pip3 install 'apache-beam[gcp]'
    ```

    <br/>

### **간단하게 beamml WordCount의 임시데이터를 버킷에 저장해봅시다.**  

* **우선 DataFlow에서도 WordCount를 실행시키려 변수를 생성합니다**  

    ```
    # PROJECT=dataflowtest-310002
    # BUCKET=nasa_storage
    # REGION=asia-northeast3
    ```

