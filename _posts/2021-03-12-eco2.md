---
layout: post
title: "[DATA] - Apache EcoSystem Sub Project"
author: nasa1515
categories: DATA
date: 2021-03-11 11:36
comments: true
cover: "/assets/1800-550.jpg"
tags: DATA
---



## **Apache EcoSystem Sub Project**


<br/>

**머리말**  

**이전 포스트에서 Hadoop EcoSystem 중 Core Project에 대해서 다뤘었습니다.**   
**이번 포스트에서는 데이터를 수집하거나 DB화 하는 오픈소스들의 모음인**  
**SUB Project들에 대해서 다룹니다.**  




  


 
---

**DATA 시리즈**

**이론**



 - [Apache Spark](https://nasa1515.github.io/data/2021/03/03/spark.html)


**실습** 

 - [Azure Synapse Analytics](https://nasa1515.github.io/data/2021/02/25/azure-synapse.html)
 - [Azure VM에 Apache Spark v3.0 Standalone 설치 With Zeppelin](https://nasa1515.github.io/data/2021/03/04/Spark2.html)
 - [Hadoop 3.3.0 Full Distribute mode infra 구축](https://nasa1515.github.io/data/2021/03/08/hadoop.html)
 - [Apache Spark v3.0 on yarn 설치 With Zeppelin](https://nasa1515.github.io/data/2021/03/10/spark-yarn.html)

---



**목차**


- [Hadoop EcoSystem Sub Project](#a1)
- [Hadoop Ecosystem](#a2)
- [Hadoop EcoSystem Core 구성 요소](#a3)
- [MapReduce](#a4)

--- 

<br/>

## **Hadoop EcoSystem Sub Project**   <a name="a1"></a>  

<br/>

![123123123](https://user-images.githubusercontent.com/69498804/110749647-be9a2880-8284-11eb-81ba-ab6f7a2e6dc1.png)





**[이전포스트](https://nasa1515.github.io/data/2021/03/11/hadoop.html#a4)에서는 Hadoop EcoSystem의 Core Project 부분에 대해서 다뤘습니다.**  
**Core Project는 다 설명했고 이제 Hadoop Sub Project의 차례 입니다.** 

* **Hadoop Core Project : HDFS(분산 데이터 저장), MapReduce(분산 처리)**
* **``Hadoop Sub Project : 나머지 프로젝트 -> 데이터 마이닝, 수집, 분석 등을 수행한다.``**



<br/>

---

### **Zookeeper(주키퍼) - 분산 코디네이터**


![111231](https://user-images.githubusercontent.com/69498804/111092196-b984f400-8578-11eb-9c77-727e7c82d5ae.jpg)


**위의 Hadoop EcoSystem을 보면 Hadoop(코끼리)부터 꿀벌 등 배부분 동물들의 이름을 딴 것들이 많습니다.**  
**각 동물은 하나의 FramWork으로 이루어져있는데 Zookeeper는 이름으로도 그 역할이 짐작이 가능합니다.**  
**Zookeeper는 분산 시스템 간의 ``정보 공유`` 및 ``상태 체크``, ``동기화``를 처리하는 프레임워크입니다.**  
**이러한 시스템을 코디네이션 서비스 시스템이라고 부르는데.**  
**Zookeeper를 많이 사용하는 이유는 기능에 비해 시스템이 단순하기 때문입니다.**  
**분산 큐, 락, 피어 그룹 대표 산출 등의 기능을 가지는데 몇 개의 기본 기능만으로도 사용이 가능합니다.**  
**즉 간단하게 요약하면 분산 환경에서 서버들간 상호 조정이 필요한 서비스를 제공합니다.**  

*   **하나의 서버에만 서비스가 집중되지 않도록 서비스를 분산하여 조정**  
* **하나의 서버에서 처리한 결과를 다른 서버와 동기화**
* **운영(Active)서버에서 문제가 발생하면 다른 서버로 바꿔 서비스 중지 없이 제공**  
* **분산 환경을 구성하는 서버들의 환경설정을 통합적으로 관리한다.**  


<br/>

### **Oozie(우지)**  

![1_uoVl2GcziNS1uEHIt9wlOg](https://user-images.githubusercontent.com/69498804/111094519-cf95b300-857e-11eb-8c6e-7c31ab91b513.png)


**Oozie는 정식 홈페이지에 나와 있듯이 Hadoop ecosystem에서 사용하는 Workflow Scheduler(혹은 orchestration) 프레임워크이다.**

**즉 하둡의 워크플로우를 관리한다.**  
**일정한 시간이 경과하거나 또는 주기적으로 반복해서 실행될 수 있는 잡들에 대하여 관리하고,**  
**MapReduce job, pig 잡 등의 시작과 완료 그리고 실행 중 에러등의 이벤트를 Call Back 할 수 있다.**

**Oozie에서 제공하는 기능은 크게 아래의 3가지와 같다.**

#### **Scheduling**

* **특정 시간에 액션 수행**
* **주기적인 간격 이후에 액션 수행**
* **이벤트가 발생하면 액션 수행**

**Coordinating**

* **이전 액션이 성공적으로 끝나면 다음 액션 시작**

**Managing**

* **액션이 성공하거나 실패했을 때 이메일 발송**
* **액션 수행시간이나 액션의 단계를 저장**

<br/>


### **Pig (피그)**  

![Apache-Pig-Architecture-24](https://user-images.githubusercontent.com/69498804/111102796-4c7d5880-8590-11eb-8283-6c0f34676d58.png)


**하둡에 저장된 데이터를 MapReduce 코딩을 하지 않고 SQL과 유사한 스크립트를 이용해 데이터를 처리 해 API를 매우 단순화한 형태로 사용할 수 있다.**  
**간단히 Hadoop의 MapReduce API를 단순화 시킨 FrameWork으로 Join 기능등을 쉽게 처리 가능하다.**  



