---
layout: post
title: "[DATA] - Cloud 별 Big Data PlatForm AWS,GCP,AZURE"
author: nasa1515
categories: DATA
date: 2021-03-19 11:36
comments: true
cover: "/assets/1800-550.jpg"
tags: DATA
---



## **Cloud 별 Big Data PlatForm AWS,GCP,AZURE**


<br/>

**머리말**  

**AWS,GCP,AZURE Cloud 별로 ETL, DW를 다루는 Service가 다릅니다.**  
**Batch, Streaming 마다 사용하는 Service도 상이합니다.**  
**그래서 Cloud 별 사용하는 Service의 장단점을 정리해봤습니다.**  





  


 
---

**DATA 시리즈**

**이론**



 - [Apache Spark](https://nasa1515.github.io/data/2021/03/03/spark.html)


**실습** 

 - [Azure Synapse Analytics](https://nasa1515.github.io/data/2021/02/25/azure-synapse.html)
 - [Azure VM에 Apache Spark v3.0 Standalone 설치 With Zeppelin](https://nasa1515.github.io/data/2021/03/04/Spark2.html)
 - [Hadoop 3.3.0 Full Distribute mode infra 구축](https://nasa1515.github.io/data/2021/03/08/hadoop.html)
 - [Apache Spark v3.0 on yarn 설치 With Zeppelin](https://nasa1515.github.io/data/2021/03/10/spark-yarn.html)

---



**목차**


- [Apache Hadoop?](#a1)
- [Hadoop Ecosystem](#a2)
- [Hadoop EcoSystem Core 구성 요소](#a3)
- [MapReduce](#a4)

--- 

<br/>

## **AWS DP**   <a name="a1"></a>   

**AWS에서 Big data를 다루기 위한 ETL, DW Service는 다음과 같이 세개가 존재한다.**  

### **Redshift - 데이터 웨어하우스 (DW)**

![123123](https://user-images.githubusercontent.com/69498804/111718855-0c72ea00-889e-11eb-8088-8df84f5b00e1.png)

* **여러 Join 및 하위 쿼리가 포함 된 매우 복잡한 SQL과 관련된 WorkLoad에 가장 빠른 쿼리 성능을 가진다.**

* **Inventory 시스템, 금융 시스템, 소매 판매 시스템 등 다양한 소스의 데이터를  
하나의 공통 형식으로 취합해 장기간 보관하고 과거 데이터에서  
비즈니스 리포트를 작성할 필요가 있을 때 사용이 가능하다.** 

* **TPC-DS: 이러한 사례에 맞게 설계된 표준 벤치마크**  
    * **Redshift는 비정형 데이터에 최적화된 쿼리 서비스보다 최대 20배 더 빠르게 실행한다.**
    * **결론적으로 Redshift는 복잡한 정형 데이터 에 대한 쿼리에 최적화된다.** 


* **PostgreSQL을 기반.** 
    * **따라서 표준 SQL을 이용한 데이터 처리를 지원하고**  
    * **BI 도구로 분석할 수 있습니다.**  
    * **칼럼 기반으로 압축하여 데이터를 저장하고 있어서 데이터의 빠른 처리가 가능.**  

<br/>

### **EMR (Elastic Map Reduce) - 데이터 처리 프레임워크**  

![다운로드](https://user-images.githubusercontent.com/69498804/111720406-24983880-88a1-11eb-8904-ba8b8401e985.png)


* **단순히 SQL 쿼리를 실행하는 것 외에도 다양한 작업이 수행 가능하다.**  
    * **Machine Learning**
    * **그래프 분석** 
    * **데이터 변환**
    * **스트리밍 데이터등** 
    * **APP에서 필요한 코딩 작업들** 
    * **Hadoop, Spark, Presto, Hbase 등 데이터 분산 처리 프레임워크로  
    가공, 분석 인프라를 위해 클러스터를 구성하고 관리해야 합니다.**  

* **이에 대한 관리가 필요 없이 S3 데이터에 대한 쿼리를 실행하려면 Athena 사용하고**  
**Athena에서 DDL 문을 통해 테이블을 정의하면 EMR을 통해 데이터 쿼리가 가능합니다.**

<br/>



### **Athena - Presto 기반의 쿼리 서비스**

![다운로드 (1)](https://user-images.githubusercontent.com/69498804/111721719-d2a4e200-88a3-11eb-86da-b3a8ea1afac9.png)


* **서버를 설정하거나 관리할 필요 없이 S3의 데이터에 대한 쿼리를 가장 쉽게 제공한다.**  

* **Redshift가 복잡한 정형 데이터에 최적화된 쿼리 서비스인 반면**  
    **Athena는 데이터 형식 지정, 인프라 관리에 관계 없이 데이터에 대한 대화형 쿼리를 쉽게 실행할 수 있음**  


* **사이트에서 성능 문제를 해결하기 위해 일부 웹 로그에서 빠른 쿼리를 실행하기만 될 경우에 적합**
* **데이터에 대한 테이블 정의하고, 표준 SQL 사용하면 된다.**  

* **Athena DDL은 Apache Hive 기반**   
    **DDL 및 테이블/파티션을 작성/수정/삭제할 경우에 한해 Hive 쿼리 사용 가능**

<br/>

### **AWS DP Service** 

![30-aws-aws-summit-seoul-2018-11-1024](https://user-images.githubusercontent.com/69498804/111722660-a12d1600-88a5-11eb-90dd-f42abb9dbf62.jpg)



<br/>

### **AWS DP 시나리오** 

![그림1](https://user-images.githubusercontent.com/69498804/111729900-7d70cc80-88b3-11eb-8cc8-5248facdb51c.png)

* **Streaming을 처리할 때 방식은 다음과 같다** 

    * **1. kinesis straming** 
    * **2. EMR Spark straming**  
    * **3. MSK + Kafka Connect**

<br/>


### **AWS DP 시나리오 (망고플레이트)**

![mangoplate architecture diagram 14fe4bbe48ed239ad11684540669d991aef24046](https://user-images.githubusercontent.com/69498804/111730395-ad6c9f80-88b4-11eb-85be-9e014333545e.png)

* **해당 시나리오로 진행한다면 중간에 Streaming 용 kinesis 추가 필요** 
* **추가로 fluentd ec2를 k8s로 구성하는게 베스트**  

<br/>


### **AWS 시나리오 3**

![MicrosoftTeams-image](https://user-images.githubusercontent.com/69498804/111730604-1f44e900-88b5-11eb-9850-e919f413eb0b.png)
* **위 시나리오에서 Batch data의 경우 S3를 거치지 않고 EMR, RedShift에 직접 Import 가능**  

