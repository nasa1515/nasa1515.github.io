---
layout: post
title: "[DATA] - Cloud 별 Big Data PlatForm AWS,GCP,AZURE"
author: nasa1515
categories: DATA
date: 2021-03-19 11:36
comments: true
cover: "/assets/1800-550.jpg"
tags: DATA
---



## **Cloud 별 Big Data PlatForm AWS,GCP,AZURE**


<br/>

**머리말**  

**AWS,GCP,AZURE Cloud 별로 ETL, DW를 다루는 Service가 다릅니다.**  
**Batch, Streaming 마다 사용하는 Service도 상이합니다.**  
**그래서 Cloud 별 사용하는 Service의 장단점을 정리해봤습니다.**  





  


 
---

**DATA 시리즈**

**이론**



 - [Apache Spark](https://nasa1515.github.io/data/2021/03/03/spark.html)


**실습** 

 - [Azure Synapse Analytics](https://nasa1515.github.io/data/2021/02/25/azure-synapse.html)
 - [Azure VM에 Apache Spark v3.0 Standalone 설치 With Zeppelin](https://nasa1515.github.io/data/2021/03/04/Spark2.html)
 - [Hadoop 3.3.0 Full Distribute mode infra 구축](https://nasa1515.github.io/data/2021/03/08/hadoop.html)
 - [Apache Spark v3.0 on yarn 설치 With Zeppelin](https://nasa1515.github.io/data/2021/03/10/spark-yarn.html)

---



**목차**


- [AWS DP](#a1)
- [GCP DP](#a2)
- [Azure DP](#a3)


--- 

<br/>

## **AWS DP**   <a name="a1"></a>   

[전체 요약 참고](https://aws.amazon.com/ko/big-data/use-cases/)

**AWS에서 Big data를 다루기 위한 ETL, DW Service는 대표적으로 3개가 존재한다.**  

<br/>

### **Redshift - 데이터 웨어하우스 (DW)**

![123123](https://user-images.githubusercontent.com/69498804/111718855-0c72ea00-889e-11eb-8088-8df84f5b00e1.png)

* **여러 Join, 하위 쿼리가 포함 된 매우 복잡한 SQL과 관련된 WorkLoad에 가장 빠른 쿼리 성능을 가진다.**

* **Inventory 시스템, 금융 시스템, 소매 판매 시스템 등 다양한 소스의 데이터를  
하나의 공통 형식으로 취합해 장기간 보관하고 과거 데이터에서  
비즈니스 리포트를 작성할 필요가 있을 때 사용이 가능하다.** 

* **TPC-DS: 이러한 사례에 맞게 설계된 표준 벤치마크**  
    * **Redshift는 비정형 데이터에 최적화된 쿼리 서비스보다 최대 20배 더 빠르게 실행한다.**
    * **결론적으로 Redshift는 복잡한 정형 데이터 에 대한 쿼리에 최적화된다.** 


* **PostgreSQL을 기반.** 
    * **따라서 표준 SQL을 이용한 데이터 처리를 지원하고**  
    * **BI 도구로 분석할 수 있습니다.**  
    * **칼럼 기반으로 압축하여 데이터를 저장하고 있어서 데이터의 빠른 처리가 가능.**  

<br/>

### **EMR (Elastic Map Reduce) - 데이터 처리 프레임워크**  

![다운로드](https://user-images.githubusercontent.com/69498804/111720406-24983880-88a1-11eb-8904-ba8b8401e985.png)


* **단순히 SQL 쿼리를 실행하는 것 외에도 다양한 작업이 수행 가능하다.**  
    * **Machine Learning**
    * **그래프 분석** 
    * **데이터 변환**
    * **스트리밍 데이터등** 
    * **APP에서 필요한 코딩 작업들** 
    * **Hadoop, Spark, Presto, Hbase 등 데이터 분산 처리 프레임워크로  
    가공, 분석 인프라를 위해 클러스터를 구성하고 관리해야 합니다.**  

* **이에 대한 관리가 필요 없이 S3 데이터에 대한 쿼리를 실행하려면 Athena 사용하고**  
**Athena에서 DDL 문을 통해 테이블을 정의하면 EMR을 통해 데이터 쿼리가 가능합니다.**

<br/>



### **Athena - Presto 기반의 쿼리 서비스**

![다운로드 (1)](https://user-images.githubusercontent.com/69498804/111721719-d2a4e200-88a3-11eb-86da-b3a8ea1afac9.png)


* **서버를 설정하거나 관리할 필요 없이 S3의 데이터에 대한 쿼리를 가장 쉽게 제공한다.**  

* **Redshift가 복잡한 정형 데이터에 최적화된 쿼리 서비스인 반면**  
    **Athena는 데이터 형식 지정, 인프라 관리에 관계 없이 데이터에 대한 대화형 쿼리를 쉽게 실행할 수 있음**  


* **사이트에서 성능 문제를 해결하기 위해 일부 웹 로그에서 빠른 쿼리를 실행하기만 될 경우에 적합**

* **데이터에 대한 테이블 정의하고, 표준 SQL 사용하면 된다.**  

* **Athena DDL은 Apache Hive 기반**   
    **DDL 및 테이블/파티션을 작성/수정/삭제할 경우에 한해 Hive 쿼리 사용 가능**

<br/>

### **AWS DP Service** 

![30-aws-aws-summit-seoul-2018-11-1024](https://user-images.githubusercontent.com/69498804/111722660-a12d1600-88a5-11eb-90dd-f42abb9dbf62.jpg)



<br/>

### **AWS DP 시나리오** 

![그림1](https://user-images.githubusercontent.com/69498804/111729900-7d70cc80-88b3-11eb-8cc8-5248facdb51c.png)

* **Streaming을 처리할 때 방식 중 대표적인 Service** 

    * **1. kinesis straming** 
    * **2. EMR Spark straming**  
    * **3. MSK + Kafka Connect**

<br/>


### **AWS DP 시나리오 (망고플레이트)**

![mangoplate architecture diagram 14fe4bbe48ed239ad11684540669d991aef24046](https://user-images.githubusercontent.com/69498804/111730395-ad6c9f80-88b4-11eb-85be-9e014333545e.png)

* **해당 시나리오로 진행한다면 중간에 Streaming 용 kinesis 추가 필요** 
* **추가로 fluentd ec2를 k8s로 구성하는게 베스트**  

<br/>


### **AWS 시나리오 3**

![MicrosoftTeams-image](https://user-images.githubusercontent.com/69498804/111730604-1f44e900-88b5-11eb-9850-e919f413eb0b.png)
* **위 시나리오에서 Batch data의 경우 S3를 거치지 않고 EMR, RedShift에 직접 Import 가능**  

<br/>

### **AWS 시나리오 4**

[참고](https://aws.amazon.com/ko/blogs/big-data/how-smartnews-built-a-lambda-architecture-on-aws-to-analyze-customer-behavior-and-recommend-content/)

<img width="1344" alt="SmartNewsImage1a" src="https://user-images.githubusercontent.com/69498804/111731370-acd50880-88b6-11eb-8202-be64a033b833.png">


<br/>
<br/>


### **AWS Glue + Landa + data PIPELINE 사용 시나리오** 

[참고](https://aws.amazon.com/ko/blogs/korea/our-data-lake-story-how-woot-com-built-a-serverless-data-lake-on-aws/)

![캡처](https://user-images.githubusercontent.com/69498804/111732887-ec512400-88b9-11eb-9119-93330d9f7a89.JPG)

<br/>

---


## **GCP DP**   <a name="a2"></a>   

**GCP의 Big Data Service는 대표적으로 아래와 같습니다.**  

![캡처2](https://user-images.githubusercontent.com/69498804/111734659-da718000-88bd-11eb-9874-6143674dace4.JPG)

<br/>

### **Cloud Dataproc** 

[참고](https://cloud.google.com/solutions/smart-analytics)

* **Hadoop, Spark, Hive, Pig 등을 90초 이내에 GCE로 생성해서 매니지드**  
* **클러스터는 실행되는 도중에도 확장 or 축소가 가능하다.**  
* **StackDriver를 통해 모니터링 가능** 
* **Cloud Starage에 적재되어있는 (로그) 데이터의 빠른 분석 가능**  
* **데이터 마이닝, 분석에 Spark SQL 사용** 
* **DS의 크기를 알고 있거나 클러스터 크기를 직접 관리하는 경우에 적합**  



* **사용 이유 :**

    - **On premise 환경에서 Hadoop 사용시 HW가 필요하지만**   **Dataproc에서 작업하면 사용하는 동안만 리소스에 대한 비용 지불**
    - **On premise 환경의 Hadoop 작업을 클라우드로 쉽게 Migration 가능**
    - **Cloud Storage에 있는 데이터를 빠르게 분석 가능**  
    **(클러스터를 평균 90초 이내 생성하고 작업 후에 즉시 삭제)**
    - **Spark/Spark SQL를 사용하여 데이터 마이닝과 분석을 빠르게 가능**
    - **Spark Machine Learning Libraries (Mllib)을 사용하여 분류 알고리즘을 수행**
    - **배치 처리에 선점형 인스턴스를 사용하여 비용 절약 가능**


<br/>


### **Cloud DataFlow [데이터 파이프라인]** 

**Dataproc에 비해 실시간성이고, 예측불가한 크기 및 속도일때 Dataflow가 적합**

* **통합 프로그래밍 모델이자 관리 서비스 [python 가능]**
* **추출, 변환, 로드, 배치 계산, 연속 계산과 같은 광범위한 데이터 처리 패턴 개발 및 실행 가능**
* **pipe line을 구축하고, 동일한 파이프 라인이 배치 및 스트리밍 데이터에 동작**
* **데이터 처리 운영에 리소스 관리 및 성능 최적화 알아서 해준다.**

**특징**

- **Resource Management : 리소스 관리 자동화**

- **On-Demand : 모든 리소스는 주문형으로 제공되어 비즈니스 요구에 맞게 확장 가능**

- **Intelligent Work Scheduling : lagging (지연된) 작업을 동적으로 재조정 할 수 있는 자동 최적화된 작업 분할 가능**

- **Auto Scaling : 작업자가 자원을 수평으로 자동 확장 가능**

- **Unified Programming Model : Dataflow API를 사용하여 데이터 소스 관계없이 MapReduce와 같은 작업 , 강력한 data windowing, 세밀한 정확성 제어 표현**

- **Integrated : seamless data 처리를 위해 Cloud Storage, Cloud Pub/Sub, Cloud Datastore, Cloud Bigtable 및 BigQuery와 통합됨, Apache Kafka 및 HDFS와 같은 다른 소스 및 싱크와 상호 작용하도록 확장 가능**


**사용 이유**

- **데이터를 이동, 필터링, 보강, 강화하기위한 ETL (추출 / 변형 / 부하) PIPELINE**
- **데이터 분석 : 스트리밍을 사용한 배치 계산 또는 연속 계산**
- **Orchestration : 외부 서비스를 포함하여 서비스를 조정하는 파이프 라인을 만든다.**
- **Cloud Storage, Cloud Pub / Sub, BigQuery 및 Bigtable과 같은 GCP 서비스와 통합**
* **오픈 소스 Java 및 Python SDK 지원**

<br/>


### **Cloud Pub/Sub [ M:M 비동기 메시징 플랫픔]** 

* **Application에 대해 Push/Pull 구독 가능**
* **Cloud DataFlow와 연동해 파이프라인 생성 가능**
* **Dataflow 스트리밍 기반에서 사용**

<br/>

### **Cloud Datalab [시각화 용 노트북]** 

<br/>

### **Big Query [완전 관리형 DW]**

* **대규모 DS (페타)에 실시간 대화식 분석 제공** 
* **SQL 구문을 사용한 쿼리 이용 (SQL 2011)** 
* **NoOps, 관리할 인프라가 없다**  
* **장기 스토리지 가격책정은 장기간 데이터에 대해서는 자동 할인**  
* **Fully Integrated**

    **SQL 쿼리 외에도 Cloud Dataflow, Spark 및 Hadoop을 통해**   **BigQuery에서 데이터를 쉽게 읽고 쓸 수 있음**


<br/>



### **GCP 기본 데이터 처리 Cycle** 

![캡처](https://user-images.githubusercontent.com/69498804/111737370-d7c55980-88c2-11eb-8151-bae90c7f49f5.JPG)


<br/>

### **GCP 표준 DP architecture**

![2](https://user-images.githubusercontent.com/69498804/111737578-37bc0000-88c3-11eb-9473-2968fccb2bd3.JPG)


<br/>

### **GCP Proc에 Hadoop, Spark 사용 시나리오**

![google-cloud-platform-rockplace-big-data-eventmar312016-26-638](https://user-images.githubusercontent.com/69498804/111738021-fbd56a80-88c3-11eb-9747-c43964f536a7.jpg)

<br/>

### **GCP 오픈소스 사용 시나리오**

![99973A4E5A9631DA11](https://user-images.githubusercontent.com/69498804/111738146-2f17f980-88c4-11eb-8dde-a3a288caad15.png)

<br/>

### **GCP Mobile Game 플랫폼 시나리오**

![telemetry-01-reference-architecture](https://user-images.githubusercontent.com/69498804/111738282-6d151d80-88c4-11eb-85e0-af5a80939065.png)

<br/>


---



## **Azure DP**   <a name="a3"></a>   

**Azure Data Service** 

![the-azure-data-landscape](https://user-images.githubusercontent.com/69498804/111739721-de55d000-88c6-11eb-8489-b74f892974f4.jpg)


<br/>



### **Azure Databricks 사용 시나리오 1**

![advanced-analytics-on-big-data-768x426](https://user-images.githubusercontent.com/69498804/111739995-4a383880-88c7-11eb-9875-a380edf09c87.png)

<br/>

### **Event Hub 사용 시나리오**

[참고](https://docs.microsoft.com/ko-kr/azure/architecture/example-scenario/dataplate2e/data-platform-end-to-end)

![azure-data-platform-end-to-end](https://user-images.githubusercontent.com/69498804/111741428-dba8aa00-88c9-11eb-822d-9125e1ede0e1.jpg)



<br/>

### **HDInsight 사용 시나리오**

![real-time-analytics](https://user-images.githubusercontent.com/69498804/111741932-9f297e00-88ca-11eb-8aa5-f23394505436.png)

<br/>

### **Fluentd 사용 시나리오**

[참고](https://docs.microsoft.com/ko-kr/azure/architecture/solution-ideas/articles/monitor-azure-data-explorer)

![monitor-azure-data-explorer](https://user-images.githubusercontent.com/69498804/111742879-2a574380-88cc-11eb-8cae-3d5f9811db7d.png)
